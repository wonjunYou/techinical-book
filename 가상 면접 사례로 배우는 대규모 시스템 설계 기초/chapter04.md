# 처리율 제한 장치의 설계

### 처리율 제한 장치란?
클라이언트 또는 서비스가 보내는 트래픽의 처리율을 제어하기 위한 장치다.
HTTP를 예로 들면 이 장치는 특정 기간 내에 전송되는 클라이언트의 요청 횟수를 제한한다.
API 요청 횟수가 제한 장치에 정의된 임계치를 넘어서면 추가로 도달한 모든 호출은 처리가 중단(block)된다.

아래는 처리율 제한 장치가 적용되는 예시이다.
* 사용자는 초당 2회 이상 새 글을 올릴 수 없다.
* 같은 IP 주소로는 하루에 10개 이상의 계정을 생성할 수 없다.
* 같은 디바이스로는 주당 5회 이상 reward를 요청할 수 없다.

### 처리율 제한 장치의 장점
* DoS 공격에 의한 자원 고갈(resource starvation)을 방지할 수 있다.
  * 트위터는 3시간 동안 최대 300개 트윗을 올릴 수 있도록 제한한다.
* 비용 절감에 효과적일 수 있으며, 서버 과부화를 막을 수 있다.

### 1단계 : 문제 이해 및 설계 범위 확정

* 어떤 종류의 처리율 제한 장치인가? (서버 or 클라이언트)
* 어떠한 기준(ip, 사용자 id 등)으로 API 호출을 제어하는가?
* 시스템의 규모
* 분산 환경 동작 여부
* 독립 서비스인지 애플리케이션 코드에 포함되는지
* 요청이 장치에 의해 blocking된 경우 사용자에게 그 사실을 알려야 하는가?

### 2단계 : 개략적 설계안 제시 및 동의 구하기
* 어느 위치에 처리율 제한 장치를 둘 것인가?
  * 클라이언트는 부적절함. 쉽게 위변조가 가능하고 모든 클라이언트 구현 통제가 어렵다.
  * 따라서 서버측에 두거나, 처리율 제한 장치 미들웨어를 만들어서 요청을 통제하도록 한다.

* MSA 에서는 처리율 제한 장치가 API Gateway라는 컴포넌트에 구현된다.
  * 처리율 제한, SSL 종단, 사용자 인증, IP 허용 목록 등을 지원

### 처리율 제한 알고리즘

### 1. 토큰 버킷 알고리즘
토큰 버킷은 지정된 용량을 갖고, 사전 설정된 양의 토큰을 주기적으로 채운다.
꽉찬 버킷에는 더 이상의 토큰이 추가되지 않는다.(오버플로가 된 토큰은 버린다.)
![image](https://github.com/wonjunYou/techinical-book/assets/59856002/59e10e48-43f4-4476-845d-04bef23f4169)

버킷은 몇 개를 사용해야 하나?
* 통상적으로 API 엔드포인트마다 별도의 버킷을 둔다.
* IP 주소별로 처리율 제한을 걸어야 하면 IP 주소마다 버킷을 할당한다.
* 시스템 처리율 자체를 제한하고자 하면, 모든 요청이 하나의 버킷을 공유해야 함.

장점
* 구현이 쉽다.
* 메모리를 효율적으로 사용한다.
* burst of traffic도 처리 가능하다.

단점
* 버킷 크기와 토큰 공급률이라는 parameter의 적절한 값을 찾아 tuning하는 것은 어렵다.

### 2. 누출 버킷 알고리즘
토큰 버킷 알고리즘과 유사하나 요청 처리율이 고정되어 있다는 점이 다르다.
누출 버킷 알고리즘은 보통 FIFO로 구현한다.
![image](https://github.com/wonjunYou/techinical-book/assets/59856002/7facd3a6-bc1e-430a-b129-bb7a9a94fedb)

* 요청이 도착하면 큐가 가득 차 있는지 본다. 빈자리가 있는 경우에는 큐에 요청을 추가한다.
* 큐가 가득 차 있는 경우에는 새 요청은 버린다.
* 지정된 시간마다 큐에서 요청을 꺼내어 처리한다.

장점
* 큐의 크기가 제한되므로 메모리 효율적 사용
* 고정된 처리율을 가지므로 안정적 출력이 필요한 경우 적합

단점
* 단시간에 많은 트래픽이 몰리면 큐에는 요청이 쌓이고, 그 요청들을 제때 처리 못하면 최신 요청들을 버려진다.
* 두 개 인자를 갖고 있는데 이를 올바르게 튜닝하기가 어려울 수 있다.

### 3. 고정 윈도 카운터 알고리즘
* 타임라인을 고정된 간격의 윈도로 나누고, 각 윈도우마다 카운터(counter)를 붙인다.
* 요청 접수 시마다 카운터의 값이 1씩 증가한다.
* 카운터의 값이 사전에 설정된 임계치(threshold)에 도달하면 새 요청은 새 윈도가 열릴 때까지 버려진다.

![image](https://github.com/wonjunYou/techinical-book/assets/59856002/007a19ed-e2a4-4b5a-b040-4daa60dfe11a)

장점
* 메모리 효율이 좋고, 이해가 쉽다.
* 특정한 트래픽 패턴을 처리하기에 적합하다.

단점
* 윈도 경계 부근에서 일시적으로 많은 트래픽이 몰리면 기대했던 시스템의 처리 한도보다 많은 양의 요청을 처리하게 된다.

### 4. 이동 윈도 로깅 알고리즘
고정 윈도 카운터 알고리즘의 문제를 해결하기 위해 등장하였다.
![image](https://github.com/wonjunYou/techinical-book/assets/59856002/23c6afad-398a-431b-b1c8-642a2e88f3c2)

* 보통 timestamp 데이터는 redis의 sorted set같은 캐시에 보관한다.
* 새 요청이오면 만료된 타임스탬프는 제거한다.
* 요청의 타임스탬프를 로그에 추가하고, 로그의 크기가 허용치보다 같거나 작으면 요청을 시스템에 전달한다.
* 요청이 거부되더라도 로그에는 남는다.

장점 
* 어느 순간에도 허용되는 요청의 개수는 시스템의 처리율 한도를 넘지 않는다.

단점
* 다량의 메모리를 사용한다(거부된 요청의 타임스탬프도 보관하기 때문)

### 5. 이동 윈도 카운터 알고리즘
* 고정 윈도 + 이동 윈도 로깅 알고리즘의 결합이다.
![image](https://github.com/wonjunYou/techinical-book/assets/59856002/f6ad03c9-c662-4b04-89ed-3c8b08e0c86f)

* 현재 1분간의 요청 수 + 직전 1분간의 요청 수 X 이동 윈도와 직전 1분이 겹치는 비율

장점
* 이전 시간대의 평균 처리율에 따라 현재 윈도상태를 계산하므로 burst of traffic에도 잘 대응한다.
* 메모리 효율이 좋다.

단점
* 직전 시간대에 도착한 요청이 균등하게 분포되어 있다고 가정하기 때문에 다소 sparse하다.
  * 해당 문제는 큰 단점은 아니다.

### 개략적인 아키텍처
카운터는 어디에 보관할 것인가?
-> 디스크 I.O의 경우 느리므로, 캐시 메모리가 좋을 듯(Redis)

Redis는 다음과 같은 명령어를 지원한다
* INCR(카운터 + 1)
* EXPIRE(카운터에 타임아웃 설정)


### Reference(사진 자료 출처)
* https://github.com/Meet-Coder-Study/book-system-design-interview/blob/master/04%EC%9E%A5/%5B3%EC%A3%BC%EC%B0%A8%5D_4%EC%9E%A5_%EC%B2%98%EB%A6%AC%EC%9C%A8%20%EC%A0%9C%ED%95%9C%20%EC%9E%A5%EC%B9%98%EC%9D%98%20%EC%84%A4%EA%B3%84_%EA%B9%80%EA%B4%91%ED%9B%88.md